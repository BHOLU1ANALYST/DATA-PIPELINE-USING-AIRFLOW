{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f9fc31",
   "metadata": {},
   "source": [
    "# I  have not use PostgreSQL for this task ,i have knowledge of  mysql, snowflake, sql server, bigquery for this task\n",
    "\n",
    "# so i don't  have knowledge how to do in PostgreSQL, BUT I AM READY TO LEARN \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a48b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9f73178",
   "metadata": {},
   "source": [
    "## NOW I AM DOING BY USING QUERY, AS WELL AS BY READING CSV FILE\n",
    "# FIRSTLY I AM CREATING PIPELING USING QUERY \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61957c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85c38d16",
   "metadata": {},
   "source": [
    "## I HAVE USE JUST 1 QUERY BUT YOU CAN MULTIPLE QUERY LET SAY 10 OR 20 OR MORE QUERY IN THAT LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('/opt/airflow/dags/')\n",
    "from helper_func.connections import data_fetch\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import pendulum\n",
    "from datetime import timedelta,datetime, date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pretty_html_table import build_table\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a10fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CondList = {\n",
    "# Sales  Summary\n",
    "'Revenue' : {\n",
    "     'cloths sales ' : {'cloths_type': [\"boy cloth\",\"girls cloth\"], 'sales':'sum'}, \n",
    "      'electronic sales' : {'electronic_type': [\"mobile\",\"laptop\"], 'sales':'sum'},\n",
    "      'books sale' : {'book_type': [\"book\",\"novel\"], 'sales':'sum'}},}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b2755",
   "metadata": {},
   "source": [
    "##  you can write various query let 10 or 20 query and join   and  isin,like,group by....etc as per requirements in this list i.e Qlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queries(start_epoch, end_epoch):\n",
    "    Qlist = [f'''select txn_date as n_time, cloths_type,electronic_type,book_type ,sales_amt as sales from sales_txn_history \n",
    "    where txn_date >= {start_epoch} and txn_date < {end_epoch}''']      \n",
    "\n",
    "    return Qlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33261efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mis(st):\n",
    "#     date in format = yyyy,mm,dd\n",
    "    '''\n",
    "    st is datetime\n",
    "    \n",
    "    '''\n",
    "#     st = datetime(yyyy,mm,dd)\n",
    "    c_date = st.date() - timedelta(days=1)\n",
    "    start_date = datetime(c_date.year,c_date.month,1)\n",
    "    start_epoch = int(start_date.strftime('%s')) - 19800   # datetimeindex is in UTC so to convert into indian time i uses 19,800 sec i.e 5.5hr\n",
    "    end_epoch = int(st.date().strftime('%s')) - 19800\n",
    "    start_dpoch = int(c_date.strftime('%s')) - 19800\n",
    "    end_dpoch = int(st.date().strftime('%s')) - 19800\n",
    "    \n",
    "    print(start_epoch)\n",
    "    print(end_epoch)\n",
    "    \n",
    "#     Connection with source\n",
    "    fetch_class = data_fetch()\n",
    "    fetch_class.set_mysql_prod()\n",
    "    \n",
    "#  initialisation\n",
    "    index1 = 0\n",
    "    data = []\n",
    "    temp_list = []\n",
    "    \n",
    "#  fetching queries\n",
    "    Qlist  = queries(start_epoch, end_epoch)\n",
    "    \n",
    "    for id, info in CondList.items():\n",
    "        print(\"\\n ID:\", id, index1)\n",
    "        df_temp = pd.DataFrame()\n",
    "    \n",
    "        try:\n",
    "            data= fetch_class.mysql_query(Qlist[index1])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"error1\",e)\n",
    "            index1 =index1 + 1\n",
    "\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for key in info:\n",
    "            field, k = info[key].popitem()\n",
    "                try:\n",
    "                    val=data.loc[(data[list(info[key])].isin(info[key])).all(axis=1),field].agg(func = k)\n",
    "                    val2=data[(data['n_time'] >= start_dpoch) & (data['n_time'] < end_dpoch)].loc[(data[list(info[key])].isin(info[key])).all(axis=1),field].agg(func = k)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"error2\",e)\n",
    "\n",
    "                    try:\n",
    "                        val=data[field].agg(func = k)\n",
    "                        val2=data[(data['n_time'] >= start_dpoch) & (data['n_time'] < end_dpoch)].loc[(data[list(info[key])]).all(axis=1),field].agg(func = k)\n",
    "\n",
    "                    except  Exception as e:\n",
    "                        print(\"error3\",e)\n",
    "                        val=0\n",
    "                        val2=0\n",
    "        \n",
    "# val is giving data of   Last Day sales i.e today()-1\n",
    "# val2 is giving sales data of MTD \n",
    "                \n",
    "            temp_list.append([id,key, int(round(val2,0)), int(round(val,0))])\n",
    "        \n",
    "        index1 = index1 + 1\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(temp_list, columns = ['Category','Field','Last Day Data','MTD'])\n",
    "    df = df.transpose()\n",
    "    df.drop(index = 'Category', inplace = True)\n",
    "    df.reset_index(inplace = True)\n",
    "    new_header = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    df.columns = new_header\n",
    "    \n",
    "    df.drop(columns = ['Overall sales','salesback','Bonus Issued','Total Credit','Total Debit','Profit-Loss'], inplace = True)\n",
    "    print(df.columns)\n",
    "    \n",
    "    df = df[['Field','cloths_type','electronic_type','book_type','sales']]\n",
    "    df_final = df.transpose()\n",
    "    df_final.reset_index(inplace = True)\n",
    "    new_header = df_final.iloc[0]\n",
    "    df_final = df_final[1:]\n",
    "    df_final.columns = new_header\n",
    "    \n",
    "    # data cleaning\n",
    "    df_final.dropna(inplace=True)\n",
    "    df_final.drop_duplicates(inplace=True)\n",
    "    \n",
    "    output = build_table(df_final ,'blue_light')\n",
    "    \n",
    "    \n",
    "    count=0\n",
    "    ############# to find the exact match and replacing it style which gives padding to the cells\n",
    "    output=output.replace('<td style = \"background-color: #D9E1F2;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;padding: 0px 20px 0px 0px;width: auto\">','<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">')\n",
    "    output=output.replace('<td style = \"background-color: #FFFFFF;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;padding: 0px 20px 0px 0px;width: auto\">','<td style = \"background-color:white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">')\n",
    "    output=output.replace('<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;padding: 0px 20px 0px 0px;width: auto\">','<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">')\n",
    "    output=output.replace('<td style = \"background-color: white; color: black;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;padding: 0px 20px 0px 0px;width: auto\">','<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">')\n",
    "    output=output.replace('<th style = \"background-color: #D9E1F2;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">','<th>')\n",
    "\n",
    "    #############looping to find the exact match and replacing it with the header tag\n",
    "    for change in toBeChangedRow:\n",
    "        output=output.replace('<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">{}</td>\\n'.format(change),'</tr><tr><td style = \"background-color: #FFFFFF;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \"><strong>{}</strong></td>\\n<td style = \"background-color: #FFFFFF;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \"></td>\\n<td style = \"background-color: #FFFFFF;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \"></td>\\n</tr><tr><td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">{}</td>\\n'.format(Headings[count],change))\n",
    "        count=count+1\n",
    "    for i,v in df_final['Last Day Data'].items():\n",
    "        if v>0:\n",
    "            output=output.replace('<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">{}</td>'.format(v),'<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">{}</td>'.format(\"{:,}\".format(v)))\n",
    "\n",
    "    for i,v in df_final['MTD'].items():\n",
    "        if v>0:\n",
    "            output=output.replace('<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">{}</td>'.format(v),'<td style = \"background-color: white;font-family: Century Gothic, sans-serif;font-size: medium;text-align: left;width: auto;border: 1px solid black;padding: 5px; text-align: left; \">{}</td>'.format(\"{:,}\".format(v)))\n",
    "    \n",
    "    output=output.replace('<th style = \"background-color: #FFFFFF;font-family: Century Gothic, sans-serif;font-size: medium;color: #305496;text-align: left;border-bottom: 2px solid #305496;padding: 0px 20px 0px 0px;width: auto\"></th>\\n','')\n",
    "    \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e713574",
   "metadata": {},
   "source": [
    "## it will create 4 columns 'Category','Field','Last Day Data','MTD'\n",
    "## these 4 column have two types of data\n",
    "## 1. last day sales data\n",
    "## 2. MTD will return sales of  first date of sales date till today-1 of this month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'BHOLU SINGH',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2023, 5, 13),\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    \n",
    "    'email': ['bholusing.data@gmail.com'],  # Specify the email ID of the DAG creator\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': True,\n",
    "    'email_to': ['bholusing.data@gmail.com', 'anyname@gmail.com','anyname2@gmail.com'],}\n",
    "\n",
    "dag = DAG(\n",
    "    'sales_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='ETL pipeline for processing sales data',\n",
    "    schedule_interval='0 0 * * *',\n",
    "    #schedule_interval='@daily',\n",
    "    catchup=False,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9d32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f929b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data():\n",
    "    my_dataframe = mis(st)\n",
    "    return my_dataframe\n",
    "\n",
    "def load_data():\n",
    "    transformed_data = my_dataframe()\n",
    "    return my_dataframe\n",
    "\n",
    "extract_task = PythonOperator(task_id='extract_task',python_callable=extract_data,dag=dag,)\n",
    "load_task = PythonOperator(task_id='load_task',python_callable=load_data,dag=dag,)\n",
    "\n",
    "extract_task >> transform_task >> load_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfacc0a4",
   "metadata": {},
   "source": [
    "# I CAN ALSO CREATE A METHOD IN WILL YOU CAN STORE ALL THE ABOVE LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2235477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e1d1999",
   "metadata": {},
   "source": [
    "# Now use VS CODE IDE and run this above code and go to local host of  AIRFLOW and trigger DAG \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb374aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79c0a97e",
   "metadata": {},
   "source": [
    "# It will send reports/summary on given mail on daily basis on scheduled time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f296ca",
   "metadata": {},
   "source": [
    "#### ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# VIA CSV FILE READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from airflow.operators.email_operator import EmailOperator\n",
    "\n",
    "# Define the DAG\n",
    "default_args = {'owner': 'BHOLU SINGH','start_date': datetime(2023, 5, 13),}\n",
    "\n",
    "dag = DAG('sales_pipeline',default_args=default_args,schedule_interval='0 0 * * *',)\n",
    "\n",
    "# Define the tasks\n",
    "def extract_data():\n",
    "    df = pd.read_csv('/path/to/your/sales_data.csv')\n",
    "    return df\n",
    "\n",
    "def transform_data(df):\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_data(df):\n",
    "    df.to_csv('/path/to/save/transformed_data.csv', index=False)\n",
    "    return html\n",
    "\n",
    "def send_email():\n",
    "    # Send an email\n",
    "    subject = 'sales Pipeline Report'\n",
    "    body = 'The sales pipeline has completed successfully.'\n",
    "    to = 'bholu.data@gmail.com'\n",
    "    email_task = EmailOperator(\n",
    "        task_id='send_email_task',\n",
    "        to=to,\n",
    "        subject=subject,\n",
    "        html_content=body,\n",
    "        dag=dag,\n",
    "    )\n",
    "    return email_task\n",
    "\n",
    "# Define the tasks using PythonOperator\n",
    "extract_task = PythonOperator(\n",
    "    task_id='extract_task',\n",
    "    python_callable=extract_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "transform_task = PythonOperator(\n",
    "    task_id='transform_task',\n",
    "    python_callable=transform_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "load_task = PythonOperator(\n",
    "    task_id='load_task',\n",
    "    python_callable=load_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "email_task = PythonOperator(\n",
    "    task_id='send_email_task',\n",
    "    python_callable=send_email,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Set task dependencies\n",
    "extract_task >> transform_task >> load_task >> email_task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf54ad",
   "metadata": {},
   "source": [
    "# in above code you can use various concept also like select only required column,transform specific column as per requirements....etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e29939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
